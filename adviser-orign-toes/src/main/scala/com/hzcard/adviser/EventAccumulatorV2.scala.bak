package com.hzcard.adviser

import org.apache.spark.util.AccumulatorV2
import java.util.concurrent.ConcurrentHashMap
import com.hzcard.adviser.Main.EventComponent
import com.hzcard.adviser.Main.EventComponent
import com.fasterxml.jackson.annotation.JsonIgnore

class EventAccumulatorV2 extends AccumulatorV2[EventComponent, ConcurrentHashMap[String, EventEntity]] {

  val _synchronizedMap = new ConcurrentHashMap[String, EventEntity]

  override def reset() {
    _synchronizedMap.clear()
  }
  override def add(inEvn: EventComponent) {
    val nEntity = EventEntity(inEvn)
    if (isZero() || !_synchronizedMap.containsKey(nEntity.requesResponseKey))
      _synchronizedMap.put(nEntity.requesResponseKey, nEntity)
    else {
      if (_synchronizedMap.containsKey(nEntity.requesResponseKey)) {
        _synchronizedMap.get(nEntity.requesResponseKey).mergerEvent(inEvn)
      }
    }
  }
  override def copy(): AccumulatorV2[EventComponent, ConcurrentHashMap[String, EventEntity]] = {
    val ventAccumulatorV2 = new EventAccumulatorV2()
    ventAccumulatorV2._synchronizedMap.putAll(_synchronizedMap)
    ventAccumulatorV2
  }
  override def isZero() = {
    _synchronizedMap.isEmpty()
  }

  override def merge(other: AccumulatorV2[EventComponent, ConcurrentHashMap[String, EventEntity]]) = other match {
    case o: EventAccumulatorV2 => {
      val ite = other.value.entrySet().iterator()
      while (ite.hasNext()) {
        val oSE = ite.next();
        if (_synchronizedMap.contains(oSE.getKey))
          _synchronizedMap.get(oSE.getKey).mergerEventEntity(oSE.getValue)
        else
          _synchronizedMap.put(oSE.getKey, oSE.getValue)
      }
    }
    case _ => throw new UnsupportedOperationException(
      s"Cannot merge ${this.getClass.getName} with ${other.getClass.getName}")
  }

  override def value = {
    _synchronizedMap
  }

}